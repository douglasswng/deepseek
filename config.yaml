raw_train_data_dir: ./data/raw/train
raw_val_data_dir: ./data/raw/val
raw_test_data_dir: ./data/raw/test

processed_train_data_dir: ./data/processed/train
processed_val_data_dir: ./data/processed/val
processed_test_data_dir: ./data/processed/test

tokeniser_dir: ./artifacts/tokeniser
deepseek_v3_ckpt_dir: ./artifacts/deepseek-v3

tokeniser_training:
  vocab_size: 50000
  min_frequency: 2 # min num occurences to be added to vocab
  chunk_size: 50000 # read size when training

model_training:
  max_len: 1024 # max number of tokens
  stride: 512 # amount of overlap between training sequences
  batch_size: 8
  num_epochs: 100
  mtp_weight: 0.2 # weight of the MTP loss
  learning_rate: 0.0001
  weight_decay: 0.01
  min_learning_rate: 0.00001
  warmup_steps: 100